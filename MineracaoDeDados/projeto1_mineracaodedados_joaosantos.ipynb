{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projeto 1 - Mineração de Dados\n",
    "#### João Santos de Sousa Filho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy  as  np \n",
    "import  pandas  as  pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wpbc.data')\n",
    "df_original = df\n",
    "for column in df:\n",
    "    if (df[column].dtype == type(object)):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "df_original.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Como o conjunto de dados veio com uma variavel objeto o que impossibilita alguns treinamentos, usamos o modulo preprocessing da biblioteca sklearn para mapear os dois valores N e R para 0 e 1 respectivamente.</p>\n",
    "<p>Verificamos também que não existem valores Nulos ou faltantes. Presseguiremos então com o treinamento</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objetivo A\n",
    "<p>Predição de uma das medidas com base nas demais.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>5</td>        <th>  R-squared:         </th> <td>   0.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.691</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   14.17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 23 Sep 2020</td> <th>  Prob (F-statistic):</th> <td>4.11e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:24:09</td>     <th>  Log-Likelihood:    </th> <td> -349.85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   177</td>      <th>  AIC:               </th> <td>   759.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   147</td>      <th>  BIC:               </th> <td>   855.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    30</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>18.02</th>    <td>   -0.5006</td> <td>    1.831</td> <td>   -0.273</td> <td> 0.785</td> <td>   -4.119</td> <td>    3.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>27.6</th>     <td>    0.0963</td> <td>    0.111</td> <td>    0.871</td> <td> 0.385</td> <td>   -0.122</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>117.5</th>    <td>    0.0531</td> <td>    0.278</td> <td>    0.191</td> <td> 0.849</td> <td>   -0.496</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1013</th>     <td>    0.0033</td> <td>    0.006</td> <td>    0.548</td> <td> 0.585</td> <td>   -0.009</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.09489</th>  <td>   24.9672</td> <td>   37.466</td> <td>    0.666</td> <td> 0.506</td> <td>  -49.075</td> <td>   99.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.1036</th>   <td>  -15.9140</td> <td>   15.732</td> <td>   -1.012</td> <td> 0.313</td> <td>  -47.005</td> <td>   15.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.1086</th>   <td>  -13.3968</td> <td>   12.379</td> <td>   -1.082</td> <td> 0.281</td> <td>  -37.861</td> <td>   11.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.07055</th>  <td>   24.4143</td> <td>   25.269</td> <td>    0.966</td> <td> 0.336</td> <td>  -25.522</td> <td>   74.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.1865</th>   <td>    2.9158</td> <td>   12.785</td> <td>    0.228</td> <td> 0.820</td> <td>  -22.350</td> <td>   28.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.06333</th>  <td>   15.6399</td> <td>   67.167</td> <td>    0.233</td> <td> 0.816</td> <td> -117.097</td> <td>  148.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.6249</th>   <td>   -5.4147</td> <td>    4.773</td> <td>   -1.134</td> <td> 0.258</td> <td>  -14.848</td> <td>    4.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1.89</th>     <td>    0.5158</td> <td>    0.671</td> <td>    0.769</td> <td> 0.443</td> <td>   -0.810</td> <td>    1.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3.972</th>    <td>    0.6869</td> <td>    0.624</td> <td>    1.101</td> <td> 0.273</td> <td>   -0.546</td> <td>    1.919</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>71.55</th>    <td>   -0.0011</td> <td>    0.022</td> <td>   -0.050</td> <td> 0.960</td> <td>   -0.045</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.004433</th> <td>   -2.4820</td> <td>  123.734</td> <td>   -0.020</td> <td> 0.984</td> <td> -247.010</td> <td>  242.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.01421</th>  <td>   28.9186</td> <td>   42.298</td> <td>    0.684</td> <td> 0.495</td> <td>  -54.672</td> <td>  112.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.03233</th>  <td>   -7.5886</td> <td>   34.727</td> <td>   -0.219</td> <td> 0.827</td> <td>  -76.217</td> <td>   61.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.009854</th> <td>    2.2425</td> <td>   77.678</td> <td>    0.029</td> <td> 0.977</td> <td> -151.268</td> <td>  155.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.01694</th>  <td>   16.2032</td> <td>   39.443</td> <td>    0.411</td> <td> 0.682</td> <td>  -61.746</td> <td>   94.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.003495</th> <td> -300.8014</td> <td>  304.659</td> <td>   -0.987</td> <td> 0.325</td> <td> -902.879</td> <td>  301.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>21.63</th>    <td>    0.4729</td> <td>    0.704</td> <td>    0.672</td> <td> 0.503</td> <td>   -0.918</td> <td>    1.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>37.08</th>    <td>   -0.1171</td> <td>    0.102</td> <td>   -1.145</td> <td> 0.254</td> <td>   -0.319</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>139.7</th>    <td>   -0.0557</td> <td>    0.073</td> <td>   -0.765</td> <td> 0.445</td> <td>   -0.200</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1436</th>     <td>   -0.0003</td> <td>    0.004</td> <td>   -0.086</td> <td> 0.932</td> <td>   -0.008</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.1195</th>   <td>   -4.4900</td> <td>   20.179</td> <td>   -0.223</td> <td> 0.824</td> <td>  -44.369</td> <td>   35.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.1926</th>   <td>    0.8704</td> <td>    5.271</td> <td>    0.165</td> <td> 0.869</td> <td>   -9.547</td> <td>   11.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.314</th>    <td>    4.6748</td> <td>    4.034</td> <td>    1.159</td> <td> 0.248</td> <td>   -3.298</td> <td>   12.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.117</th>    <td>  -15.5142</td> <td>   10.782</td> <td>   -1.439</td> <td> 0.152</td> <td>  -36.821</td> <td>    5.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.2677</th>   <td>   -6.3946</td> <td>    6.534</td> <td>   -0.979</td> <td> 0.329</td> <td>  -19.308</td> <td>    6.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.08113</th>  <td>   35.7143</td> <td>   35.654</td> <td>    1.002</td> <td> 0.318</td> <td>  -34.746</td> <td>  106.175</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>63.760</td> <th>  Durbin-Watson:     </th> <td>   1.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 149.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.609</td> <th>  Prob(JB):          </th> <td>4.21e-33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.140</td> <th>  Cond. No.          </th> <td>3.93e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.93e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      5   R-squared:                       0.743\n",
       "Model:                            OLS   Adj. R-squared:                  0.691\n",
       "Method:                 Least Squares   F-statistic:                     14.17\n",
       "Date:                Wed, 23 Sep 2020   Prob (F-statistic):           4.11e-30\n",
       "Time:                        23:24:09   Log-Likelihood:                -349.85\n",
       "No. Observations:                 177   AIC:                             759.7\n",
       "Df Residuals:                     147   BIC:                             855.0\n",
       "Df Model:                          30                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "18.02         -0.5006      1.831     -0.273      0.785      -4.119       3.118\n",
       "27.6           0.0963      0.111      0.871      0.385      -0.122       0.315\n",
       "117.5          0.0531      0.278      0.191      0.849      -0.496       0.602\n",
       "1013           0.0033      0.006      0.548      0.585      -0.009       0.015\n",
       "0.09489       24.9672     37.466      0.666      0.506     -49.075      99.009\n",
       "0.1036       -15.9140     15.732     -1.012      0.313     -47.005      15.177\n",
       "0.1086       -13.3968     12.379     -1.082      0.281     -37.861      11.067\n",
       "0.07055       24.4143     25.269      0.966      0.336     -25.522      74.351\n",
       "0.1865         2.9158     12.785      0.228      0.820     -22.350      28.182\n",
       "0.06333       15.6399     67.167      0.233      0.816    -117.097     148.377\n",
       "0.6249        -5.4147      4.773     -1.134      0.258     -14.848       4.018\n",
       "1.89           0.5158      0.671      0.769      0.443      -0.810       1.841\n",
       "3.972          0.6869      0.624      1.101      0.273      -0.546       1.919\n",
       "71.55         -0.0011      0.022     -0.050      0.960      -0.045       0.043\n",
       "0.004433      -2.4820    123.734     -0.020      0.984    -247.010     242.046\n",
       "0.01421       28.9186     42.298      0.684      0.495     -54.672     112.509\n",
       "0.03233       -7.5886     34.727     -0.219      0.827     -76.217      61.040\n",
       "0.009854       2.2425     77.678      0.029      0.977    -151.268     155.753\n",
       "0.01694       16.2032     39.443      0.411      0.682     -61.746      94.153\n",
       "0.003495    -300.8014    304.659     -0.987      0.325    -902.879     301.276\n",
       "21.63          0.4729      0.704      0.672      0.503      -0.918       1.864\n",
       "37.08         -0.1171      0.102     -1.145      0.254      -0.319       0.085\n",
       "139.7         -0.0557      0.073     -0.765      0.445      -0.200       0.088\n",
       "1436          -0.0003      0.004     -0.086      0.932      -0.008       0.007\n",
       "0.1195        -4.4900     20.179     -0.223      0.824     -44.369      35.389\n",
       "0.1926         0.8704      5.271      0.165      0.869      -9.547      11.288\n",
       "0.314          4.6748      4.034      1.159      0.248      -3.298      12.647\n",
       "0.117        -15.5142     10.782     -1.439      0.152     -36.821       5.793\n",
       "0.2677        -6.3946      6.534     -0.979      0.329     -19.308       6.518\n",
       "0.08113       35.7143     35.654      1.002      0.318     -34.746     106.175\n",
       "==============================================================================\n",
       "Omnibus:                       63.760   Durbin-Watson:                   1.868\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              149.095\n",
       "Skew:                           1.609   Prob(JB):                     4.21e-33\n",
       "Kurtosis:                       6.140   Cond. No.                     3.93e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.93e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selecionando apenas as colunas que são referentes a metricas do tumor\n",
    "X_reg = df.drop(['119513','N','31','5','5.1'],axis=1)\n",
    "#A variavel escolhida será a que representa o tamnho do tumor(diametro) em cm.\n",
    "y_reg = df['5']\n",
    "\n",
    "#Separando o conjunto de teste e treinamento do modelo (10% do conjunto para testes)\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size = 0.1, random_state = 42)\n",
    "#treinamento\n",
    "#construindo o modelo\n",
    "model = sm.OLS(y_train_reg, X_train_reg).fit()\n",
    "y_pred_reg = model.predict(X_test_reg)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Tivemos um R² alto, poderia ser maior em caso o conjunto de dados de treino apresenta-se mais instancias.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objetivo B - Classificação de Tumores\n",
    "<p>Agora o foco é um problema de classficação, isto é, com base nas demais medidas, o modelo deve prever se o cancer é recorrente ou não.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.75\n"
     ]
    }
   ],
   "source": [
    "#Selecionando todas as colunas com exceção do codigo e da variavel escolhida para a predição\n",
    "X_class = df.drop(['119513','N'],axis=1)\n",
    "#A variavel escolhida será a que representa a recorrencia do cancer.\n",
    "y_class = df['N'].values\n",
    "knn_ca = KNeighborsClassifier(n_neighbors = 3)\n",
    "#Separando o conjunto de teste e treinamento do modelo (10% do conjunto para testes)\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size = 0.1, random_state = 42)\n",
    "knn_ca.fit(X_train_class,y_train_class)\n",
    "print(\"Score: \",knn_ca.score(X_test_class,y_test_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
